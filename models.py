import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

tweets_data = {
   'text': [
       # Tweets trÃ¨s positifs
       "Putain ce film c'Ã©tait une pure dinguerie! ğŸ”¥",
       "Cette sÃ©rie Netflix elle dÃ©chire sa mÃ¨re! ğŸ¤©",
       "Le resto Ã©tait trop de la frappe, j'suis choquÃ© ğŸ˜‹",
       "Ce match Ã©tait ouf, on les a dÃ©foncÃ©s! âš½ï¸",
       "Le nouveau son il tue tout franchement ğŸµ",
       "Trop bien cette nouvelle collection wesh ğŸ‘•",
       "Putain le jeu il est violent, meilleur fps ever! ğŸ®",
       "La soirÃ©e d'hier c'Ã©tait le feuuuu ğŸ”¥",
       "Cette nouvelle voiture elle envoie du lourd ğŸš—",
       "Le concert c'Ã©tait une pure folie wallah ğŸµ",

       # Tweets assez positifs
       "Pas mal du tout ce nouveau truc en vrai ğŸ‘Œ",
       "Franchement Ã§a passe bien leur dÃ©lire",
       "Cette formation m'a grave servi en fait",
       "Le nouveau restau il est chaud quand mÃªme",
       "Pas dÃ©gueu du tout ce plat",
       "Ce son il est vÃ©nÃ¨re en vrai ğŸµ",
       "StylÃ© ce nouveau tatouage frÃ¨re ğŸ¨",
       "Bonne ambiance Ã  la soirÃ©e hier",
       "Le film il est bon en fait",
       "Ce jeu il est plutÃ´t solide",

       # Tweets trÃ¨s nÃ©gatifs  
       "C'est vraiment de la merde leur truc... ğŸ¤®",
       "Putain mais quel connard celui-lÃ  sÃ©rieux ğŸ˜¤",
       "Ras le cul de cette appli de merde!",
       "Les fdp ils m'ont encore arnaquÃ© ğŸ˜¡",
       "Nique sa mÃ¨re ce service client",
       "C'est vraiment des bÃ¢tards lÃ -bas",
       "Mais quelle grosse merde ce jeu ğŸ®",
       "Service de merde comme d'hab ğŸ˜¤",
       "Va te faire foutre avec tes prix",
       "Trop des fils de pute ces vendeurs",

       # Tweets assez nÃ©gatifs
       "La qualitÃ© c'est devenu de la merde",
       "Ce nouveau truc il pue la merde",
       "Service client tout pÃ©tÃ© comme d'hab",
       "L'attente Ã©tait relou putain",
       "Encore en retard ces cons",
       "Ils m'ont bien niquÃ© sur ce coup",
       "Le service il craint vraiment",
       "Trop des branlos dans cette boÃ®te",
       "La bouffe Ã©tait dÃ©gueulasse",
       "Le concert c'Ã©tait de la daube"
   ],
   'positive': [1]*20 + [0]*20,
   'negative': [0]*20 + [1]*20
}

df = pd.DataFrame(tweets_data)

def clean_text(text):
   text = text.lower()
   text = re.sub(r'[^\w\s\U0001F300-\U0001F9FF]', '', text)
   text = re.sub(r'\s+', ' ', text)
   return text.strip()

df['text_clean'] = df['text'].apply(clean_text)

french_stopwords = [
   "le", "la", "les", "un", "une", "des", "du", "de", "dans", "et", "en", "au", "aux", "avec",
   "ce", "ces", "pour", "par", "sur", "pas", "plus", "oÃ¹", "mais", "ou", "donc", "ni", "car", "ne",
   "que", "qui", "quoi", "quand", "Ã ", "son", "sa", "ses", "ils", "elles", "nous", "vous", "est", 
   "sont", "cette", "cet", "aussi", "Ãªtre", "avoir", "faire", "comme", "tout", "bien", "mal", "on"
]

vectorizer = TfidfVectorizer(
   stop_words=french_stopwords,
   ngram_range=(1, 2),
   max_features=500
)

X = vectorizer.fit_transform(df['text_clean'])

# Ajout des informations de performance
print("Dataset created successfully:")
print(df)
print("\nText vectorization completed.")
print("Data split into training and test sets.")

# Split pour les deux modÃ¨les
X_train, X_test, y_train_pos, y_test_pos, y_train_neg, y_test_neg = train_test_split(
   X, df['positive'], df['negative'], test_size=0.25, random_state=42
)

# EntraÃ®nement des deux modÃ¨les
model_positive = LogisticRegression(class_weight='balanced')
model_negative = LogisticRegression(class_weight='balanced')

model_positive.fit(X_train, y_train_pos)
model_negative.fit(X_train, y_train_neg)

print("\nModel trained successfully.")

# Ã‰valuation modÃ¨le positif
y_pred_pos = model_positive.predict(X_test)
print("\nClassification report - Positive Model:")
print(classification_report(y_test_pos, y_pred_pos))
print("\nConfusion matrix - Positive Model:")
print(confusion_matrix(y_test_pos, y_pred_pos))

# Ã‰valuation modÃ¨le nÃ©gatif 
y_pred_neg = model_negative.predict(X_test)
print("\nClassification report - Negative Model:")
print(classification_report(y_test_neg, y_pred_neg))
print("\nConfusion matrix - Negative Model:")
print(confusion_matrix(y_test_neg, y_pred_neg))

def get_sentiment_score(text, vectorizer, model_pos, model_neg):
   text_clean = clean_text(text)
   text_vectorized = vectorizer.transform([text_clean])
   
   pos_proba = model_pos.predict_proba(text_vectorized)[0][1]
   neg_proba = model_neg.predict_proba(text_vectorized)[0][1]
   
   score = (pos_proba - neg_proba)  # Score entre -1 et 1
   return score

new_tweets = [
   # Positifs intenses
   "Ptain ce film Ã©tait une pure dinguerie! ğŸ”¥",
   "Meilleure soirÃ©e de ouf, merci la team! ğŸ™Œ",
   "Ce resto c'est de la frappe wesh ğŸ’¯",
   "INCROYABLE ce match putain!!! âš½ï¸",
   "Le nouveau son il tue sa mÃ¨re ğŸµ",
   
   # Positifs modÃ©rÃ©s
   "Pas mal du tout ce nouveau truc ğŸ‘Œ",
   "Franchement Ã§a passe bien ğŸ˜",
   "C'est plutÃ´t cool en vrai",
   
   # NÃ©gatifs modÃ©rÃ©s  
   "C'est de la merde leur nouveau service... ğŸ™„",
   "Putain mais quel con celui-lÃ  ğŸ˜’",
   "Ras le cul de cette appli de merde",
   
   # NÃ©gatifs intenses
   "Va niquer ta mÃ¨re @service_client ğŸ¤¬", 
   "Les fdp ils m'ont encore arnaquÃ©!! ğŸ˜¡",
   "MAIS QUELLE MERDE CE BORDEL JE PÃˆTE UN CÃ‚BLE ğŸ¤¬",
   "Vtff avec votre service pourri",
   "J'en peux plus de ces connards ğŸ˜¤",
   
   # Mixtes/ContrastÃ©s
   "La soirÃ©e Ã©tait cool mais putain ces embrouilles... ğŸ˜©",
   "Bon film mais public de merde qui fait que parler ğŸ™„",
   "Restau sympa mais service de fdp",
   "Putain le jeu il est bon en fait! ğŸ®"
]

for tweet in new_tweets:
   score = get_sentiment_score(tweet, vectorizer, model_positive, model_negative)
   print(f"Tweet: '{tweet}'\nScore: {score:.2f}\n")